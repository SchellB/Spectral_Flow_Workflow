---
title: "Supplementary file R script spectral workflow"
author: "H. den Braanker"
date: "25-8-2021"
output:
  word_document: default
  html_document: default
  pdf_document: default
code_folding: show
---

### Introduction
This script belongs to paper .... We will walk through the described pipeline with two different spectral flow cytometry datasets. Case A will use the dataset described in the paper and available at:  . Case B will use part of the files of a spectral flow cytometry dataset .. Files to download from this dataset: ...
If there are difficulties adapting the script to your own dataset, please do not hestitate to contact us: h.denbraanker@erasmusmc.nl or github.

```{r Installing packages, message=FALSE, eval=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("flowCore")
BiocManager::install("flowViz")
BiocManager::install("flowVS")
BiocManager::install("flowAI")
BiocManager::install("PeacoQC")
BiocManager::install("CATALYST")
BiocManager::install("SingleCellExperiment")

if(!requireNamespace("devtools", quietly=TRUE))
  install.packages("devtools")

devtools::install_github('saeyslab/CytoNorm')
install.packages("uwot")
install.packages("knitr")
install.packages("xlsx")
```

```{r Load packages, message=FALSE}
set.seed(123)
library(flowCore)
library(flowViz)
library(flowVS)
library(flowAI)
library(PeacoQC)
library(CATALYST)
library(CytoNorm)
library(SingleCellExperiment)
library(uwot)
library(knitr)
library(xlsx)
```


##Case A: Spectral flow cytometry dataset - ...

### Manual quality control and pregating of spectral flow cytometry data
Before proceeding to automated analyses, several manual gating steps are required for quality control and cleaning of the data. Manually exclude doublets and dead cells. After, gate your population of interest and export it as FCS files. Save these FCS files in a new folder *FCS files* in your working directory.

### Importing spectral flowcytometry data
The exported FCS 3.1 files can be stored in a folder *FCS files* and subsequently imported into the R environment with the FlowCore package. We will apply transformation of the data later, so transformation=FALSE. Furthermore, to prevent truncation of the data, truncate_max_range=FALSE. 

```{r Importing FCS files A}
fcs.dir<- "C:/Users/koala/Documents/GitHub/CMF-pipeline/FCS_NKact"

fcs_data <- read.flowSet(path=fcs.dir, pattern="*.fcs", transformation = FALSE, truncate_max_range = FALSE) #fcs_data will be a FlowSet object
```

Construct a data frame of your panel:

```{r Panel-A}

panel <- read.csv2("C:/Users/koala/Documents/GitHub/CMF-pipeline/Data/panelNKact.csv", row.names = 1)

markers <- panel$antigen
chnls <- panel$channel
names(markers) <- chnls
markernames(fcs_data) <- markers
markernames(fcs_data)

```

```{r Panel table-A, echo=FALSE}
kable(panel)
```

### Transforming spectral flow cytometry data

First, determine which markers you want to transform. You only have to transform the channels that you used for your experiment.
```{r Transforming data A-1}
library(dplyr)
markerstotransform <- panel$channel[panel$marker_class=="type"]
```

Before calculating cofactors with the FlowVS package, we will downsample our data. Including more cells in finding the optimum cofactor will come with a computational cost. Bartlett’s statistics (Y-axis) are computed from density peaks after data is transformed by different cofactors (X-axis). An optimum cofactor is obtained where Bartlett’s statistics is minimum (indicated by red circles). The estParamFlowVs function will show you the plots were it based its values on. It is advised to export your cofactor data as an csv or excel file, this is for reproducibility purposes.

##### Transforming your data with the FlowVS package

```{r Transforming data with FlowVS package A, eval=FALSE }
Downsampling_FlowSet <- function(x, samplesize , replace=TRUE, prob=NULL){
  if(missing(samplesize))
    samplesize <- min(flowCore::fsApply(x,nrow))
  flowCore::fsApply(x, function(ff){
    i <- sample(nrow(ff), size = samplesize, replace=replace, prob)
    ff[i,]
  })
}

fcs_data_small <- Downsampling_FlowSet(x=fcs_data, samplesize = 2000) #samplesize is the number of cells included, you can include more cells.

pdf(file="Output/cofactorTransform.pdf")
cofactors <- estParamFlowVS(fcs_data_small, channels=markerstotransform)
dev.off()
cofactordata <- data.frame(markerstotransform, cofactors)
write.csv2(x=cofactordata, file="Output/cofactordata.csv", row.names=F) #csv file

cofactordata <- read.csv2("Output/cofactordata.csv")

fcs_transform <- transFlowVS(fcs_data, channels = cofactordata$markerstotransform, cofactordata$cofactors)
filenames <- sampleNames(fcs_data)
sampleNames(fcs_transform) <- filenames
markernames(fcs_transform) <- markers
markernames(fcs_transform)


```

##### Transforming your data with a fixed cofactor

```{r Transforming data with a fixed cofactor A, results='hide'}
cofactor <- 3000
l <- length(markerstotransform)
cofactors<- rep(cofactor, l)

fcs_transform <- transFlowVS(fcs_data, channels = markerstotransform, cofactors)
filenames <- sampleNames(fcs_data)
sampleNames(fcs_transform) <- filenames

save(fcs_transform, fcs_transform_small, file="fcsTransformed.Rdata")
load("fcsTransformed.Rdata")
```

To evaluate the data transformation, you can visualize density plots of markers with the FlowViz package. 

```{r densityplots A}
pdf(file="Output/cofactorTransformPlots.pdf")
densityplot(~., fcs_data[[1]]) #density plot before transformation, you can replace `FJComp-BB515-A` by . to view all markers.

densityplot(~., fcs_transform[[1]]) # density plot after transformation
dev.off()

``` 

### Automatic quality control of flow cytometry data 
Either flowAI or peacoQC package can be used to clean flow cytometry data. For Case A we demonstrate FlowAI, for Case B peacoQC.

No pre-gated Time gate:
```{r peacoQC, eval=FALSE}
for(i in 1:9){
  ff <-fcs_transform[[i]]
  
  channels=markerstotransform
  
  peacoqc_res <- PeacoQC(ff, channels, determine_good_cells = "all", IT_limit=0.55, MAD=5, save_fcs = TRUE, plot=TRUE, output_directory = "PeacoQCresults")
} 

fcs.dir <- file.path(getwd(),"PeacoQCresults/PeacoQC_results/fcs_files")

fcs_transform <- read.flowSet(path=fcs.dir, transformation=FALSE, truncate_max_range = FALSE) #construct new flowset from the cleaned files
```


### Batch effects
The next step is to correct batch effects, we will use the Cytonorm package to align our different files from different batches. We measured the same samples on different days (technical replicates) 

```{r batch effect correction-1, message=FALSE}
fcs.dir<- file.path(getwd(), "Transformed FCS files")

files <- list.files(fcs.dir, pattern = "fcs$")
train_files <- file.path(fcs.dir, list.files(fcs.dir, pattern="MALA44"))
validation_files <- file.path(getwd(), "Transformed FCS files", list.files(fcs.dir, pattern="fcs$"))
fsom <- prepareFlowSOM(train_files, colsToUse = markerstotransform, transformList = NULL, FlowSOM.params = list(xdim=10,ydim=10, nClus=20, scale=FALSE))
``` 

To check if clustering is appropriate:

```{r batch effect correction-2, eval=FALSE}
cvs <- testCV(fsom, cluster_values = c(5,10,15))
```

If the clusters are impacted by batch effects, CV values of >1.5/2 will occur, than you can also choose to put FlowSOM.params to NULL and skip clustering.

Next, load a metadata file which includes at least a sample_id and a column defining the batches. You can include a column with filenames. 

```{r batch effect correction-3}
library(readxl)
md <-read_excel("C:/Users/koala/Documents/GitHub/CMF-pipeline/Data/metadataNKact.xlsx")
train <- subset(md, md$file_name %in% grep("MALA44", md$file_name, value = TRUE))
```

```{r batch effect correction-4, echo=FALSE}
kable(md)
```

```{r batch effect correction-5, results='hide', message=FALSE}
fcs.dir<- file.path(getwd(), "Transformed FCS files")
file_names <- list.files(fcs.dir, pattern = "fcs$")
sort(file_names)
file_name <- fsApply(fcs_transform, identifier)
sort(file_name)

file_name == file_names #check if the order of files in the directory and order of files in FlowSet object are matching

md <- data.frame(sort(file_name), md, row.names=NULL)


model <- CytoNorm.train(files = train_files,
                        labels = train$NK_id,
                        channels = markerstotransform,
                        transformList = NULL,
                        FlowSOM.params = NULL,
                        normMethod.train = QuantileNorm.train,
                        normParams = list(nQ = 101,
                                          goal = "mean"),
                        seed = 1,
                        verbose = TRUE)

CytoNorm.normalize(model = model,
                   files = validation_files,
                   labels = labels,
                   transformList = NULL,
                   transformList.reverse = NULL,
                   normMethod.normalize = QuantileNorm.normalize,
                   outputDir = "Normalized",
                   prefix = "Norm_",
                   clean = TRUE,
                   verbose = TRUE)

outdir <- file.path(getwd(), "Normalized")
fcs_norm <- read.flowSet(path=outdir, pattern="*Norm_tf", transformation = FALSE, truncate_max_range = FALSE)



densityplot(~"FJComp-APC-Vio 770-A", fcs_transform[10])#before normalization

densityplot(~"FJComp-APC-Vio 770-A", fcs_norm[13])#after normalization

save(fcs_norm, file="fcsTransformedNorm.Rdata")

```

At this point, you can take the FCS files from the Transformed files directory or Normalized FCS files directory and load these files into Cytosplore. More information about Cytosplore is available at: [https://www.cytosplore.org/]. You can skip arcsinh transformation for the data in Cytosplore.

